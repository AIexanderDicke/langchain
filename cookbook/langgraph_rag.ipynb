{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d6741-262e-4dfa-934d-1a567b872559",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://python.langchain.com/docs/langgraph\n",
    "https://python.langchain.com/docs/use_cases/question_answering/conversational_retrieval_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384cc48-0425-4e8f-aafc-cfb8e56025c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bebdc-be71-4130-ab9d-42f09f87658b",
   "metadata": {},
   "source": [
    "## Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565a6d44-2c9f-4fff-b1ec-eea05df9350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=7500, chunk_overlap=100\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfa37e-f226-4a55-883a-a2e98870a7e4",
   "metadata": {},
   "source": [
    "## Retriever Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "704b15f1-d10b-4723-b9e4-80ea88f07d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Searches and returns information about agents, prompt engineering, and adversarial attacks.\",\n",
    ")\n",
    "\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259b5dd-1af1-4d1d-b468-91840c2ecd6b",
   "metadata": {},
   "source": [
    "We can now wrap these tools in a simple ToolExecutor. \n",
    "\n",
    "This is a real simple class that takes in a ToolInvocation and calls that tool, returning the output. \n",
    "\n",
    "A ToolInvocation is any class with tool and tool_input attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66fc63e8-3f86-4edf-b7e8-801a01a45d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98b9a35b-e028-4333-af6e-e38ac30a8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a130aa2e-be49-495d-bcb2-aea4990afb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "model = model.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276001c5-c079-4e5b-9f42-81a06704d200",
   "metadata": {},
   "source": [
    "## Define the agent state\n",
    "\n",
    "Graph is parameterized by a state object that it passes around to each node -\n",
    "\n",
    "* `SET` specific attributes on the state (e.g. overwrite the existing values)\n",
    "* `ADD` to the existing attribute\n",
    "\n",
    "State -\n",
    "\n",
    "* List of messages\n",
    "\n",
    "We want each node to just add messages to that list - \n",
    "\n",
    "* `TypedDict` with one key (messages) \n",
    "* Annotate it so that the messages attribute is always added to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21784b41-8115-4d45-bd3c-5809c749f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251feeea-c9a0-404a-8b55-bef3020bb5e2",
   "metadata": {},
   "source": [
    "## Nodes\n",
    "\n",
    "* Function - A function to invoke tools: if the agent decides to take an action, this node will then execute that action.\n",
    "* Runnable - The agent: responsible for deciding what (if any) actions to take.\n",
    "\n",
    "## Edges\n",
    "\n",
    "Some of these edges may be conditional.\n",
    "\n",
    "The reason they are conditional is that based on the output of a node, one of several paths may be taken.\n",
    "\n",
    "Conditional edge will take an agent decision - \n",
    "\n",
    "* Action - then the function to invoke tools should be called.\n",
    "* If the agent said that it was finished, then it should finish\n",
    "  \n",
    "Normal Edge will take an agent decision - \n",
    "\n",
    "* After the tools are invoked, it should always go back to the agent to decide what to do next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "add509d8-6682-4127-8d95-13dd37d79702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolInvocation\n",
    "import json\n",
    "from langchain_core.messages import FunctionMessage\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    # Otherwise if there is, we continue\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state):\n",
    "    messages = state['messages']\n",
    "    response = model.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Define the function to execute tools\n",
    "def call_tool(state):\n",
    "    messages = state['messages']\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input=json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"]),\n",
    "    )\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    print(\"---DOCS---\")\n",
    "    print(response)\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    \n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd5797-1782-4d78-a277-8196d13f3e1b",
   "metadata": {},
   "source": [
    "## Graph\n",
    "\n",
    "* Start with an agent, `call_model`\n",
    "* Agent make a decision to call a function\n",
    "* If so, then `action` to call tool (retriever)\n",
    "* Then call agent with the tool output added to messages (`state`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62ed2feb-136f-4ac7-8b85-89ce6f342ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", call_tool)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e09ca9f-e36d-4ef4-a0d5-79fdbada9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Finally we pass in a mapping.\n",
    "    # The keys are strings, and the values are other nodes.\n",
    "    # END is a special node marking that the graph should finish.\n",
    "    # What will happen is we will call `should_continue`, and then the output of that\n",
    "    # will be matched against the keys in this mapping.\n",
    "    # Based on which one it matches, that node will then be called.\n",
    "    {\n",
    "        # If `tools`, then we call the tool node.\n",
    "        \"continue\": \"action\",\n",
    "        # Otherwise we finish.\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb69dbb9-91ee-4868-8c3c-93af3cd885be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What are the types of agent memory?'),\n",
       "  AIMessage(content=\"There are several types of agent memory:\\n\\n1. Episodic Memory: This type of memory allows an agent to remember specific events or episodes that it has experienced. It enables the agent to recall past experiences and use them to inform its current actions.\\n\\n2. Semantic Memory: Semantic memory refers to the general knowledge and facts that an agent has acquired over time. It includes information about concepts, categories, relationships, and rules. Semantic memory helps the agent understand and interpret the world around it.\\n\\n3. Procedural Memory: Procedural memory involves the memory of how to perform specific tasks or actions. It includes knowledge of procedures, skills, and routines. Procedural memory allows the agent to execute learned actions without conscious effort.\\n\\n4. Working Memory: Working memory is a temporary storage system that holds information for a short period of time. It is used for processing and manipulating information in real-time. Working memory is essential for tasks that require attention, problem-solving, and decision-making.\\n\\n5. Emotional Memory: Emotional memory involves the storage and retrieval of emotional experiences. It allows the agent to remember and respond to emotionally significant events or stimuli. Emotional memory plays a role in shaping the agent's behavior and decision-making.\\n\\nThese types of memory can vary in their implementation and capacity depending on the specific agent or AI system.\")]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "inputs = {\"messages\": [HumanMessage(content=\"What are the types of agent memory?\")]}\n",
    "app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c659a82-b149-405a-b335-43b1f5a1fb60",
   "metadata": {},
   "source": [
    "Trace:\n",
    "\n",
    "https://smith.langchain.com/public/3e22b4f9-9a08-4e64-bab8-47c3843c2418/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
